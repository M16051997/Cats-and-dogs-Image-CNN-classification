{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The task is to build a model to predict the category of an animal: dog or cat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wd5UUJ8ap6vR"
   },
   "outputs": [],
   "source": [
    "# 4 steps are required to build a CNN: \n",
    "#1.Convolution, \n",
    "#2.Max pooling, \n",
    "#3.Flattening, and \n",
    "#4.Full connection\n",
    "\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JHYAjG2CqBbw"
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "# Convolution is a linear operation involving the multiplication of weights with the input.\n",
    "# The multiplication is performed between an array of input data and a 2D array of weights known as filter or kernel. \n",
    "# It is represented like ana array of 0 and 1\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "\n",
    "#The pooling operation provides spatial variance making the system capable of recognizing an object with some varied appearance.\n",
    "# pooling basically helps reduce the number of parameters and computations present in the network. \n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#The output from the final Pooling layer which is flattened is the input of the fully connected layer.\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rvHe3xrbqBqO"
   },
   "outputs": [],
   "source": [
    "# Compile the CNN by choosing an SGD algorithm, a loss function, and performance metrics. \n",
    "# We use binary_crossentropy for binary classification, and use categorical_crossentropy for multiple classification problem.\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Oo55xKVxqCCl"
   },
   "outputs": [],
   "source": [
    "# Image augmentation is a method of applying different kinds of transformation to original images resulting in multiple transformed copies of the same image. \n",
    "# The images are different from each other in certain aspects because of shifting, rotating, flipping techniques. \n",
    "# So, we are using the Keras ImageDataGenerator class to augment our images.\n",
    "#create an object of ImageDataGenerator, for augmenting train set\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "\n",
    "##create another object of ImageDataGenerator, for augmenting test set\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use flow_from_directory(directory) method from Keras Official website to load images and apply augmentation. \n",
    "# This is why we structured the data folders in a specific way so that the class of each image can be identified from its folder name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "qhCbVch_rKq9",
    "outputId": "2e6ee35b-0059-4c36-8eeb-fcb02f88a7db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#apply image augmentation on train set by resizing all images to 64x64 and creating batches of 32 images.\n",
    "training_set = train_datagen.flow_from_directory(r'C:\\Users\\M.komala\\OneDrive\\Desktop\\keras\\dog vs cat\\dataset\\training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 30,\n",
    "                                                 class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hlujVcwZrd2i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#apply image augmentation on test set by resizing all images to 64x64 and creating batches of 32 images.\n",
    "test_set = test_datagen.flow_from_directory(r'C:\\Users\\M.komala\\OneDrive\\Desktop\\keras\\dog vs cat\\dataset\\test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 30,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M.komala\\AppData\\Local\\Temp\\ipykernel_9924\\3171078237.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 626s 2s/step - loss: 0.6608 - accuracy: 0.6036 - val_loss: 0.7445 - val_accuracy: 0.5519\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 338s 1s/step - loss: 0.5988 - accuracy: 0.6781 - val_loss: 0.5671 - val_accuracy: 0.7159\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 227s 910ms/step - loss: 0.5724 - accuracy: 0.7012 - val_loss: 0.5456 - val_accuracy: 0.7376\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 170s 678ms/step - loss: 0.5490 - accuracy: 0.7156 - val_loss: 0.5535 - val_accuracy: 0.7302\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 55s 220ms/step - loss: 0.5453 - accuracy: 0.7187 - val_loss: 0.5311 - val_accuracy: 0.7519\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 43s 173ms/step - loss: 0.5317 - accuracy: 0.7311 - val_loss: 0.5499 - val_accuracy: 0.7265\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 44s 174ms/step - loss: 0.5282 - accuracy: 0.7323 - val_loss: 0.5257 - val_accuracy: 0.7460\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 122s 490ms/step - loss: 0.5114 - accuracy: 0.7418 - val_loss: 0.5525 - val_accuracy: 0.7370\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 176s 703ms/step - loss: 0.4993 - accuracy: 0.7503 - val_loss: 0.5439 - val_accuracy: 0.7429\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 50s 200ms/step - loss: 0.4884 - accuracy: 0.7613 - val_loss: 0.5401 - val_accuracy: 0.7339\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 45s 178ms/step - loss: 0.4880 - accuracy: 0.7611 - val_loss: 0.5189 - val_accuracy: 0.7497\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 43s 173ms/step - loss: 0.4837 - accuracy: 0.7665 - val_loss: 0.5193 - val_accuracy: 0.7513\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 43s 173ms/step - loss: 0.4676 - accuracy: 0.7757 - val_loss: 0.6363 - val_accuracy: 0.6804\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.4712 - accuracy: 0.7744 - val_loss: 0.5953 - val_accuracy: 0.7095\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 43s 171ms/step - loss: 0.4575 - accuracy: 0.7826 - val_loss: 0.5240 - val_accuracy: 0.7508\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 43s 174ms/step - loss: 0.4515 - accuracy: 0.7809 - val_loss: 0.5183 - val_accuracy: 0.7640\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 43s 170ms/step - loss: 0.4494 - accuracy: 0.7826 - val_loss: 0.5390 - val_accuracy: 0.7455\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 46s 186ms/step - loss: 0.4371 - accuracy: 0.7931 - val_loss: 0.5479 - val_accuracy: 0.7376\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 43s 170ms/step - loss: 0.4346 - accuracy: 0.7937 - val_loss: 0.5461 - val_accuracy: 0.7476\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 44s 174ms/step - loss: 0.4358 - accuracy: 0.7933 - val_loss: 0.5381 - val_accuracy: 0.7471\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 44s 174ms/step - loss: 0.4177 - accuracy: 0.8029 - val_loss: 0.5336 - val_accuracy: 0.7619\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 43s 172ms/step - loss: 0.4177 - accuracy: 0.8040 - val_loss: 0.5137 - val_accuracy: 0.7640\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 43s 170ms/step - loss: 0.4083 - accuracy: 0.8147 - val_loss: 0.5379 - val_accuracy: 0.7603\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.4039 - accuracy: 0.8123 - val_loss: 0.5353 - val_accuracy: 0.7646\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 43s 171ms/step - loss: 0.3999 - accuracy: 0.8160 - val_loss: 0.5255 - val_accuracy: 0.7630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a6736029b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = (8000/32),\n",
    "                         epochs = 25,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = (2000/32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the image 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image =  keras.utils.load_img(r'C:\\Users\\M.komala\\OneDrive\\Desktop\\keras\\CNN\\data\\test\\test set\\111 (1).jpg', \n",
    "                            target_size = (64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add channel dimension for image\n",
    "test_image = tf.keras.utils.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "##add batch dimension for image\n",
    "test_image = np.expand_dims(test_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 203ms/step\n"
     ]
    }
   ],
   "source": [
    "result = classifier.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a Dog Image\n"
     ]
    }
   ],
   "source": [
    "if result [0][0] ==0:\n",
    "    print('It is a Cat Image')\n",
    "else:\n",
    "    print('It is a Dog Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices\n",
    "\n",
    "# when the output is '0' it is cat\n",
    "# when the output is '1' it is Dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict 2nd Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image1 =  keras.utils.load_img(r'C:\\Users\\M.komala\\OneDrive\\Desktop\\keras\\CNN\\data\\train\\train set\\9.jpg',\n",
    "                                    target_size = (64, 64))\n",
    "\n",
    "test_image1 = tf.keras.utils.img_to_array(test_image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "##add batch dimension for image\n",
    "test_image1 = np.expand_dims(test_image1, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 219ms/step\n"
     ]
    }
   ],
   "source": [
    "result = classifier.predict(test_image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a Cat Image\n"
     ]
    }
   ],
   "source": [
    "if result [0][0] ==0:\n",
    "    print('It is a Cat Image')\n",
    "else:\n",
    "    print('It is a Dog Image')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
